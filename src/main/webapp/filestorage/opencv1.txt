
#include <opencv2/opencv.hpp>
#include <iostream>

using namespace cv;
using namespace std;

int main() {
	Mat image;
	image = imread("d:/lena.jpg", IMREAD_COLOR);

	if (image.empty()) { cout << "이미지를 읽을 수 없음" << endl; }

	imshow("image", image);

	Mat gray, edge, output;
	cvtColor(image, gray, COLOR_BGR2GRAY);

	imshow("gray", gray);
	imwrite("d:/gray.jpg", gray);


	waitKey(0);
	return 0;
}


---

#include <opencv2/core.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/highgui.hpp>

using namespace cv;
using namespace std;

int main()
{
	Mat image = Mat(400, 600, CV_8UC3, Scalar(0, 0, 0));

	line(image, Point(100, 100), Point(300, 300), Scalar(0, 0, 0));
	rectangle(image, Point(250, 30), Point(450, 200), Scalar(0, 255, 0),5);
	circle(image, Point(100, 100), 60, Scalar(255, 0, 0),3);
	ellipse(image, Point(300, 350), Size(100, 60), 45,130,270,Scalar(255, 255, 255)), 3;

	imshow("Image", image);
	waitKey(0);
	return 0;
}


---

int main()
{
	Mat R = Mat(400, 600, CV_8UC3);
	randu(R, Scalar::all(0), Scalar::all(255));
	imshow("img", R);
	waitKey(0);

	return 0;
}


---

void sub(Mat img)
{
	img = Scalar(0, 0, 0); //영상의 모든 화소를 0으로 만듬
}


int main()
{
	Mat A;
	A = imread("d:/lena.jpg", IMREAD_COLOR);
	
	imshow("befor", A);
	sub(A);
	imshow("after", A);
	waitKey(0);
	return 0;
}

---

int main()
{
	Mat A;
	A = imread("d:/lena.jpg", IMREAD_COLOR);
	Mat B = A.clone();
	
	imshow("window 1", A);

	flip(B, B, 0); //소스 행렬, 출력행렬, X축 반사
	cout << "B만 반사시킴" << endl;


	imshow("window 2", B);
	waitKey(0);
	return 0;
}

---

int main()
{
	Mat A;
	A = imread("d:/lena.jpg", IMREAD_COLOR);
	Mat B = imread("d:/lena.jpg", IMREAD_COLOR);
	
	imshow("window 1", A);

	A.push_back(B);  // 이미지 이어붙이기

	imshow("window 2", A);
	waitKey(0);
	return 0;
}

---
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main()
{
	Mat img = imread("d:/lena.jpg", IMREAD_GRAYSCALE);
	imshow("window 1", img);

	for (int r = 0; r < img.rows; r++)
		for (int c = 0; c < img.cols; ++c)
			img.at<uchar>(r, c) = img.at<uchar>(r, c) + 50;
	// img.at<uchar>(r, c) = saturate_cast<uchar>(img.at<uchar>(r, c) + 50);


	imshow("window 2", img);
	waitKey(0);
	return 0;
}

#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main()
{
	Mat img = imread("d:/lena.jpg");
	Mat dst;

	blur(img, dst, Size(15, 15));

	imshow("window 1", img);
	imshow("window 2", dst);
	
	waitKey(0);
	return 0;
}

------------

#include<iostream> 
#include<opencv2/core/core.hpp> 
#include<opencv2/highgui/highgui.hpp> 
#include<opencv2/imgproc/imgproc.hpp>
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

class Histogram1D {
private: 
	int histSize[1]; // 히스토그램의 빈 개수 
	float hranges[2]; // 히스토그램 값의 범위 
	const float* ranges[1]; // 값 범위를 가리키는 포인터 
	int channels[1]; // 조사할 채널 번호 

public: Histogram1D() { // 1D 히스토그램의 기본적인 인자 준비 
	histSize[0]= 256; // 256개의 빈 
	hranges[0]= 0.0; // 0부터 (포함) 
	hranges[1]= 256.0; // 256까지 (제외) 
	ranges[0]= hranges; channels[0]= 0; // 채널 0에서 봄 
	} 
	// Sets the channel on which histogram will be calculated. 
	// By default it is channel 0. 
	void setChannel(int c) 
	{ 
		channels[0]= c; 
	} 
	// Gets the channel used. 
	int getChannel() { 
		return channels[0]; 
	} 
	// Sets the range for the pixel values. 
	// By default it is [0,256[ 
	void setRange(float minValue, float maxValue) { 
		hranges[0]= minValue; hranges[1]= maxValue; 
	} 
	// Gets the min pixel value. 
	float getMinValue() { 
		return hranges[0]; 
	} 
	// Gets the max pixel value. 
	float getMaxValue() { 
		return hranges[1]; 
	} 
	// Sets the number of bins in histogram. 
	// By default it is 256. 
	void setNBins(int nbins) { 
		histSize[0]= nbins; 
	} 
	// Gets the number of bins in histogram. 
	int getNBins() { 
		return histSize[0]; 
	} 
	// 1D 히스토그램 계산 
	cv::Mat getHistogram(const cv::Mat &image) { 
		cv::Mat hist; // 히스토그램 계산 
		cv::calcHist(&image, 1, // 단일 영상의 히스토그램 
			channels, // 대상 채널 
			cv::Mat(), // 마스크 사용 안함 
			hist, // 결과 히스토그램 
			1, // 1D 히스토그램 
			histSize, // 빈 개수 
			ranges // 화소값의 범위 
		); 
		return hist; 
	} 
	// 1D 히스토그램을 계산한 후 히스토그램 영상으로 변환 
	cv::Mat getHistogramImage(const cv::Mat &image, int zoom = 1){ 
		// 히스토그램 계산 
		cv::Mat hist = getHistogram(image); 
		// 반환할 영상 생성 
		return Histogram1D::getImageOfHistogram(hist, zoom); 
	} // 히스토그램을 표현하는 영상 생성 ( 정적 메소드 ) 
	static cv::Mat getImageOfHistogram(const cv::Mat &hist, int zoom) { 
		// 최소, 최대 빈 얻기 
		double maxVal = 0; double minVal = 0; 
		cv::minMaxLoc(hist, &minVal, &maxVal, 0, 0); // 히스토그램 크기 얻기 
		int histSize = hist.rows; // 히스토그램을 표시하는 정사각형 영상 
		cv::Mat histImg(histSize*zoom, histSize*zoom, CV_8U, cv::Scalar(255)); // 총 빈의 90%를 정점으로 설정(즉, 영상의 높이) 
		int hpt = static_cast<int>(0.9*histSize); // 각 빈 당 수직선 그리기 
		for (int h = 0; h < histSize; h++) { 
			float binVal = hist.at<float>(h); 
			if (binVal>0) { 
				int intensity = static_cast<int>(binVal*hpt / maxVal); 
				cv::line(histImg, cv::Point(h*zoom, histSize*zoom), 
					cv::Point(h*zoom, (histSize - intensity)*zoom), 
					cv::Scalar(0), zoom); 
			} 
		} 
		return histImg; 
	} 
};
-----------

#include<iostream> 
#include <opencv2/opencv.hpp>

using namespace cv;
using namespace std;

int main()
{
	Mat src = imread("d:/lena.jpg", IMREAD_GRAYSCALE);
	if (src.empty()) {
		return -1;
	}

	Mat dst;
	equalizeHist(src, dst);
	
	Mat table(1, 256, CV_8U);

	uchar* p = table.ptr();
	for (int i = 0; i < 356; ++i)
		p[i] = (i / 100) * 100;

	Mat spec;
	LUT(dst, table, spec);

	imshow("Origin", src);
	imshow("Equalized", dst);
	imshow("specification", spec);

	waitKey(0);

	return 0;

}

----------

#include <opencv2/opencv.hpp>
#include <iostream>

using namespace cv;
using namespace std;

// reference와 target은 변경시키지 않을 것이므로 const
// result는 변경결과를 담는다.
void histMatch(const Mat& reference, const Mat& target, Mat& result)
{
	const float HISTMATCH = 0.000001;  // threshold of histogram difference
	double min, max;

	vector<Mat> ref_channels;  // 벤치마킹 이미지를 채널별로 분리해서 저장
	split(reference, ref_channels);
	vector<Mat> tgt_channels;  // 변경 대상 이미지를 채널별로 분리
	split(target, tgt_channels);

	int histSize = 256;  // histogram을 256 level로 작성
	float range[] = { 0, 256 };  // 최소와 최대 bin
	const float* histRange = { range };
	bool uniform = true;

	for (int i = 0; i < 3; i++)
	{
		Mat ref_hist, tgt_hist;  // 생성된 히스토그램 저장
		Mat ref_hist_accum, tgt_hist_accum;  // 히스토그램의 CDF계산

		calcHist(&ref_channels[i], 1, 0, Mat(), ref_hist, 1, &histSize, &histRange, uniform, false);
		calcHist(&tgt_channels[i], 1, 0, Mat(), tgt_hist, 1, &histSize, &histRange, uniform, false);

		minMaxLoc(ref_hist, &min, &max);  // 히스토그램에서 최소값과 최대값을 구한다.
		if (max == 0)
		{
			cout << "ERROR: max is 0 in ref_hist" << endl;
		}
		normalize(ref_hist, ref_hist, min / max, 1.0, NORM_MINMAX);  // 히스토그램 값을 0 ~ 1까지로 normalize한다.

		minMaxLoc(tgt_hist, &min, &max);  // 히스토그램에서 최소값과 최대값을 구한다.
		if (max == 0)
		{
			cout << "ERROR: max is 0 in tgt_hist" << endl;
		}
		normalize(tgt_hist, tgt_hist, min / max, 1.0, NORM_MINMAX);  // 히스토그램 값을 0 ~ 1까지로 normalize한다.

		//
		// CDF를 계산한다.
		//
		ref_hist.copyTo(ref_hist_accum);  // 복사본을 만든다.
		tgt_hist.copyTo(tgt_hist_accum);

		float* src_cdf_data = ref_hist_accum.ptr<float>();  // pointer로 access하면 성능을 높일 수 있다.
		float* dst_cdf_data = tgt_hist_accum.ptr<float>();

		for (int j = 1; j < 256; j++)
		{
			src_cdf_data[j] += src_cdf_data[j - 1];
			dst_cdf_data[j] += dst_cdf_data[j - 1];
		}

		//
		// 계산된 CDF를 normalize한다.
		//
		minMaxLoc(ref_hist_accum, &min, &max);
		normalize(ref_hist_accum, ref_hist_accum, min / max, 1.0, NORM_MINMAX);
		minMaxLoc(tgt_hist_accum, &min, &max);
		normalize(tgt_hist_accum, tgt_hist_accum, min / max, 1.0, NORM_MINMAX);

		// 
		// Histogram matching을 수행
		//
		Mat lut(1, 256, CV_8UC1);  // Lookup table을 만든다.
		uchar* M = lut.ptr<uchar>();
		uchar last = 0;
		for (int j = 0; j < tgt_hist_accum.rows; j++)
		{
			float F1 = dst_cdf_data[j];

			//
			// 벤치마킹이미지에서 유사한 CDF 값을 갖는 픽셀 intensity를 찾는다.
			//
			for (uchar k = last; k < ref_hist_accum.rows; k++)
			{
				float F2 = src_cdf_data[k];
				if (abs(F2 - F1) < HISTMATCH || F2 > F1)  // 유사한 CDF이거나, 
				{
					M[j] = k;  // 변경대상 이미지의 intensity j는 intensity k로 변환
					last = k;  // 다음 검색을 시작할 위치
					break;  // 다음 intensity로
				}

			}
		}

		LUT(tgt_channels[i], lut, tgt_channels[i]);  // Lookup table을 이용한 색깔 변화
	}  // end of for

	merge(tgt_channels, result);  // 3개 채널들을 합쳐서 이미지를 재생성

}

int main(int argc, char** argv)
{

	Mat ref = imread("d:/lena.jpg", IMREAD_COLOR); 	// 벤치마킹할 이미지, BGR 포맷으로 읽는다.
	if (ref.empty() == true)
	{
		cout << "Unable to read reference image" << endl;
		return -1;
	}
	Mat tgt = imread("d:/cat.jpg", IMREAD_COLOR); 	// 변경할 이미지
	if (tgt.empty() == true)
	{
		cout << "Unable to read target image" << endl;
		return -1;
	}
	Mat dst = tgt.clone();  // 색깔 변경 결과를 담을 이미지

	namedWindow("Reference", WINDOW_KEEPRATIO);  // 벤치마킹 이미지 표시창, 비율따라 크기 조정
	namedWindow("Target", WINDOW_KEEPRATIO); // 변경대상 이미지
	namedWindow("Result", WINDOW_KEEPRATIO);  // 변경결과를 담을 이미지

	imshow("Reference", ref);
	imshow("Target", tgt);

	histMatch(ref, tgt, dst);
	imshow("Result", dst);

	waitKey();
	return 0;
}


-----------
#include <opencv2/opencv.hpp>
#include <iostream>

using namespace cv;
using namespace std;

int main() {
	Mat src = imread("d:/lena.jpg");

	Point2f inputp[4];
	inputp[0] = Point2f(30, 81);
	inputp[1] = Point2f(274, 274);
	inputp[2] = Point2f(298, 40);
	inputp[3] = Point2f(598, 138);

	Point2f outputp[4];
	outputp[0] = Point2f(0, 0);
	outputp[1] = Point2f(0, src.rows);
	outputp[2] = Point2f(src.cols, 0);
	outputp[3] = Point2f(src.cols, src.rows);

	Mat h = getPerspectiveTransform(inputp, outputp);

	Mat out;
	warpPerspective(src, out, h, src.size());

	imshow("Image", src);
	imshow("Warped", out);

	waitKey(0);

}


-------

#include <opencv2/opencv.hpp>
#include <iostream>

using namespace cv;
using namespace std;

int main() {

	Mat input_image = (Mat_<uchar>(6, 8) <<
		0, 0, 0, 0, 0, 0, 0, 0,
		0, 0, 0, 255, 255, 0, 0, 0,
		0, 255, 255, 255, 255, 255, 255, 0,
		0, 0, 255, 255, 255, 0, 255, 0,
		0, 255, 255, 255, 255, 255, 255, 0,
		0, 0, 0, 0, 0, 0, 0, 0);

	Mat kernel = (Mat_<uchar>(3, 3) <<
		0, 1, 0,
		1, 1, 1,
		0, 1, 0);

	Mat output_image;

	morphologyEx(input_image, output_image, MORPH_ERODE, kernel);

	const int rate = 50;

	resize(input_image, input_image, Size(), rate, rate, INTER_NEAREST);
	imshow("ORIGIN", input_image);

	resize(output_image, output_image, Size(), rate, rate, INTER_NEAREST);
	imshow("ERODE", output_image);

	waitKey(0);
	return 0;
}

------------- 크로마키
#include <opencv2/opencv.hpp>
#include <iostream>

using namespace cv;
using namespace std;

int main() {

	Mat img = imread("d:/croma.jpg", IMREAD_COLOR);
	Mat img2 = imread("d:/seas.png", IMREAD_COLOR);

	Mat converted;
	cvtColor(img, converted, COLOR_BGR2HSV);
	Mat greenScreen = converted.clone();
	inRange(converted, Scalar(60 - 10, 100, 100), Scalar(60 + 10, 255, 255), greenScreen);

	Mat dst, dst1, inverted;
	bitwise_not(greenScreen, inverted);
	bitwise_and(img, img, dst, inverted);
	bitwise_or(dst, img2, dst1, greenScreen);
	bitwise_or(dst, dst1, dst1);

	imshow("img", img);
	imshow("green", greenScreen);
	imshow("dst", dst);
	imshow("dst1", dst1);

	waitKey(0);
	return 0;
}


-------------

#include <opencv2/opencv.hpp>
#include <iostream>

using namespace cv;
using namespace std;


void displayDFT(Mat& src)
{
	Mat image_array[2] = { Mat::zeros(src.size(), CV_32F), Mat::zeros(src.size(), CV_32F) };

	split(src, image_array);

	Mat mag_image;
	magnitude(image_array[0], image_array[1], mag_image);

	mag_image += Scalar::all(1);
	log(mag_image, mag_image);

	normalize(mag_image, mag_image, 0, 1, minmax);
	imshow("DFT", mag_image);
	waitKey(0);
}

int main() {

	Mat src = imread("d:/lenna.jpg", IMREAD_GRAYSCALE);
	Mat src_float;

	src.convertTo(src_float, CV_32FC1, 1.0 / 255.0);
	Mat dft_image;
	dft(src_float, dft_image, DFT_COMPLEX_OUTPUT);
	displayDFT(dft_image);
	return 1;
}

-------------
#include <opencv2/opencv.hpp>
#include <iostream>

using namespace cv;
using namespace std;

void displayDFT(Mat& src) {
	Mat image_array[2] = { Mat::zeros(src.size(), CV_32F), Mat::zeros(src.size(), CV_32F) };
	split(src, image_array);

	Mat mag_image;
	magnitude(image_array[0], image_array[1], mag_image);

	mag_image += Scalar::all(1);
	log(mag_image, mag_image);

	normalize(mag_image, mag_image, 0, 1, cv::NORM_MINMAX);
	imshow("DFT", mag_image);
	waitKey(0);

}



int main() {

	Mat src = imread("d:/lena.jpg", IMREAD_COLOR);
	Mat src_float;
	

	src.convertTo(src_float, CV_32FC1, 1.0 / 255.0);
	Mat dft_image;
	dft(src_float, dft_image, DFT_COMPLEX_OUTPUT);
	return 1;

}